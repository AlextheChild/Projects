{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    ")\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU available. \n",
      "No GPU available. \n"
     ]
    }
   ],
   "source": [
    "# check cpu and gpu\n",
    "\n",
    "num_cpus = len(tf.config.list_physical_devices(\"CPU\"))\n",
    "num_gpus = len(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "if num_cpus > 0:\n",
    "    print(\"CPU available. \")\n",
    "else:\n",
    "    print(\"No CPU available. \")\n",
    "\n",
    "if num_gpus > 0:\n",
    "    print(\"GPU available. \")\n",
    "else:\n",
    "    print(\"No GPU available. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of images and their lists of bounding boxes\n",
    "\n",
    "rows = open(\"data/data.csv\").read().strip().split(\"\\n\")\n",
    "\n",
    "images_and_box_lists = {}\n",
    "\n",
    "current_image = \"images/0.png\"\n",
    "temp_box_list = []\n",
    "for row in rows:\n",
    "    row = row.split(\",\")\n",
    "\n",
    "    if row[0] != current_image:\n",
    "        images_and_box_lists.update({current_image: temp_box_list})\n",
    "        current_image = row[0]\n",
    "        temp_box_list = []\n",
    "    temp_box_list.append([int(row[1]), int(row[2]), int(row[3]), int(row[4])])\n",
    "images_and_box_lists.update({current_image: temp_box_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(box1, box2):\n",
    "    box1_x1 = box1[0]\n",
    "    box1_y1 = box1[1]\n",
    "    box1_w = box1[2]\n",
    "    box1_h = box1[3]\n",
    "\n",
    "    box1_x2 = box1_x1 + box1_w\n",
    "    box1_y2 = box1_y1 + box1_h\n",
    "\n",
    "    box2_x1 = box2[0]\n",
    "    box2_y1 = box2[1]\n",
    "    box2_w = box2[2]\n",
    "    box2_h = box2[3]\n",
    "\n",
    "    box2_x2 = box2_x1 + box2_w\n",
    "    box2_y2 = box2_y1 + box2_h\n",
    "\n",
    "    intersection_x1 = max(box1_x1, box2_x1)\n",
    "    intersection_y1 = max(box1_y1, box2_y1)\n",
    "    intersection_x2 = min(box1_x2, box2_x2)\n",
    "    intersection_y2 = min(box1_y2, box2_y2)\n",
    "\n",
    "    intersection_area = max(0, intersection_x2 - intersection_x1) * max(\n",
    "        0, intersection_y2 - intersection_y1\n",
    "    )\n",
    "\n",
    "    box1_area = box1_w * box1_h\n",
    "    box2_area = box2_w * box2_h\n",
    "\n",
    "    return intersection_area / float(box1_area + box2_area - intersection_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split images and make labels list (0:55)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "ious = []\n",
    "\n",
    "w = 320\n",
    "h = 360\n",
    "\n",
    "for key in images_and_box_lists:\n",
    "    full_image = Image.open(\"data/\" + key)\n",
    "\n",
    "    # loop through windows\n",
    "    for window_y1 in range(0, 1800, h):\n",
    "        for window_x1 in range(0, 2880, w):\n",
    "            window_x2 = window_x1 + w\n",
    "            window_y2 = window_y1 + h\n",
    "\n",
    "            cropped_image = full_image.crop(\n",
    "                [window_x1, window_y1, window_x2, window_y2]\n",
    "            )\n",
    "            label = 0\n",
    "\n",
    "            # get max iou for all balloon boxes in list\n",
    "            window_box = [window_x1, window_y1, w, h]\n",
    "            max_iou = 0\n",
    "            for balloon_box in images_and_box_lists.get(key):\n",
    "                iou = intersection_over_union(window_box, balloon_box)\n",
    "\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "\n",
    "            ious.append(max_iou)\n",
    "\n",
    "            if max_iou > 0.2:\n",
    "                label = 1\n",
    "\n",
    "            processed_image = cropped_image.resize([32, 36])\n",
    "            processed_image = np.asarray(processed_image)\n",
    "            processed_image = processed_image.astype(\"float32\") / 255\n",
    "            images.append(processed_image)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0i\n",
      "count: 0 iou: 0\n",
      "1i\n",
      "count: 1 iou: 0\n",
      "2i\n",
      "count: 2 iou: 0\n",
      "3i\n",
      "count: 3 iou: 0\n",
      "4i\n",
      "count: 4 iou: 0\n",
      "5i\n",
      "count: 5 iou: 0\n",
      "6i\n",
      "count: 6 iou: 0\n",
      "7i\n",
      "count: 7 iou: 0.02410442244938432\n",
      "8i\n",
      "count: 8 iou: 0.022169437846397466\n",
      "9i\n",
      "count: 9 iou: 0\n",
      "10i\n",
      "count: 10 iou: 0\n",
      "11i\n",
      "count: 11 iou: 0\n",
      "12i\n",
      "count: 12 iou: 0\n",
      "13i\n",
      "count: 13 iou: 0\n",
      "14i\n",
      "count: 14 iou: 0\n",
      "15i\n",
      "count: 15 iou: 0\n",
      "16i\n",
      "count: 16 iou: 0.31942766886555796\n",
      "17i\n",
      "count: 17 iou: 0.28713858424725824\n",
      "18i\n",
      "count: 18 iou: 0\n",
      "19i\n",
      "count: 19 iou: 0\n",
      "20i\n",
      "count: 20 iou: 0\n",
      "21i\n",
      "count: 21 iou: 0.21978207363125543\n",
      "22i\n",
      "count: 22 iou: 0.3624714931776893\n",
      "23i\n",
      "count: 23 iou: 0\n",
      "24i\n",
      "count: 24 iou: 0\n"
     ]
    }
   ],
   "source": [
    "# draw labels for split images\n",
    "\n",
    "import cv2\n",
    "\n",
    "# ! arrow keys\n",
    "\n",
    "enumeration = list(enumerate(images))\n",
    "\n",
    "index = 0\n",
    "while index < 18000:\n",
    "    print(str(index) + \"i\")\n",
    "    i, image = enumeration[index]\n",
    "\n",
    "    name = str(labels[i])\n",
    "    cv2.namedWindow(name)\n",
    "    cv2.moveWindow(name, 0, 0)\n",
    "\n",
    "    image = cv2.resize(image, (320, 360), interpolation=cv2.INTER_NEAREST)\n",
    "    cv2.imshow(name, image)\n",
    "    cv2.resizeWindow(name, 320, 360)\n",
    "\n",
    "    print(\"count: \" + str(i) + \" iou: \" + str(ious[i]))\n",
    "\n",
    "    key = cv2.waitKey(0)\n",
    "\n",
    "    if key == ord(\"d\"):\n",
    "        index += 1\n",
    "        cv2.destroyAllWindows()\n",
    "    elif key == ord(\"a\"):\n",
    "        index -= 1\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a grid on every image where it thinks the things are\n",
    "\n",
    "import os\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "path = \"data/images\"\n",
    "directory = os.listdir(path)\n",
    "\n",
    "index = 0\n",
    "font = ImageFont.load_default(100)\n",
    "\n",
    "for file in directory:\n",
    "    image = Image.open(path + \"/\" + file)\n",
    "\n",
    "    # draw box\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for y in range(0, 1800, h):\n",
    "        for x in range(0, 2880, w):\n",
    "            draw.rectangle(((x, y), (x + 320, y + 360)), outline=\"black\", width=3)\n",
    "            if labels[index] == 1:\n",
    "                draw.rectangle(((x, y), (x + 320, y + 360)), outline=\"red\", width=6)\n",
    "                draw.text((x+120, y+180), str(round(ious[index], 1)), font = font, fill=\"black\", stroke_fill=\"white\", stroke_width=3)\n",
    "\n",
    "            index += 1\n",
    "\n",
    "    image.save(\"labeled_images/images/\" + file)\n",
    "\n",
    "path = \"data/flipped_images\"\n",
    "directory = os.listdir(path)\n",
    "\n",
    "for file in directory:\n",
    "    image = Image.open(path + \"/\" + file)\n",
    "\n",
    "    # draw box\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for y in range(0, 1800, h):\n",
    "        for x in range(0, 2880, w):\n",
    "            draw.rectangle(((x, y), (x + 320, y + 360)), outline=\"black\", width=3)\n",
    "            if labels[index] == 1:\n",
    "                draw.rectangle(((x, y), (x + 320, y + 360)), outline=\"red\", width=6)\n",
    "                draw.text((x+120, y+180), str(round(ious[index], 1)), font = font, fill=\"black\", stroke_fill=\"white\", stroke_width=3)\n",
    "\n",
    "            index += 1\n",
    "\n",
    "    image.save(\"labeled_images/flipped_images/\" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16\n",
    "\n",
    "vgg = VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_tensor=keras.layers.Input(shape=(32, 36, 3)),\n",
    ")\n",
    "\n",
    "vgg.trainable = False\n",
    "\n",
    "window_x1 = vgg.output\n",
    "window_x1 = Flatten()(window_x1)\n",
    "window_x1 = Dense(128, activation=\"relu\")(window_x1)\n",
    "window_x1 = Dense(64, activation=\"relu\")(window_x1)\n",
    "window_x1 = Dense(32, activation=\"relu\")(window_x1)\n",
    "window_x1 = Dense(1, activation=\"sigmoid\")(window_x1)\n",
    "model = keras.Model(inputs=vgg.input, outputs=window_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "train_images, test_images = np.split(images, [int(len(images) * 0.8)])\n",
    "train_boxes, test_boxes = np.split(labels, [int(len(labels) * 0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(reduction=\"sum_over_batch_size\", name=\"mse\"),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_boxes,\n",
    "    epochs=20,\n",
    "    validation_data=(test_images, test_boxes),\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "model.evaluate(test_images, test_boxes, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "model.save(\"models/vgg_good_20_20.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
