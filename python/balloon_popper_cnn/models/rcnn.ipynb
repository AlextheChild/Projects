{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    ")\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU available. \n",
      "No GPU available. \n"
     ]
    }
   ],
   "source": [
    "# check cpu and gpu\n",
    "\n",
    "num_cpus = len(tf.config.list_physical_devices('CPU'))\n",
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "if num_cpus > 0:\n",
    "    print(\"CPU available. \")\n",
    "else:\n",
    "    print(\"No CPU available. \")\n",
    "\n",
    "if num_gpus > 0:\n",
    "    print(\"GPU available. \")\n",
    "else:\n",
    "    print(\"No GPU available. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of images and their lists of bounding boxes\n",
    "\n",
    "rows = open(\"data/data.csv\").read().strip().split(\"\\n\")\n",
    "\n",
    "images_and_box_lists = {}\n",
    "\n",
    "current_image = \"images/0.png\"\n",
    "temp_box_list = []\n",
    "for row in rows: \n",
    "    row = row.split(\",\")\n",
    "\n",
    "    if(row[0] != current_image): \n",
    "        images_and_box_lists.update({current_image : temp_box_list})\n",
    "        current_image = row[0]\n",
    "        temp_box_list = []\n",
    "    temp_box_list.append([row[1], row[2], row[3], row[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split images and make labels list\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "split_images = []\n",
    "labels = []\n",
    "\n",
    "for key in images_and_box_lists:\n",
    "    full_image = Image.open(\"data/\" + key)\n",
    "\n",
    "    # loop through xxx boxes\n",
    "    for y in range(0, 1800, 360):\n",
    "        for x in range(0, 2880, 320):\n",
    "            image = full_image.crop()\n",
    "\n",
    "            # ! maybe can use IOU here\n",
    "        \n",
    "            split_images.append(full_image)\n",
    "            labels.append\n",
    "\n",
    "# image name, bboxes for fully sized image\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw labels for split images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1342156391.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    input_tensor=keras.layers.Input(shape=(, 3)),\u001b[0m\n\u001b[1;37m                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# vgg16\n",
    "\n",
    "vgg = VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_tensor=keras.layers.Input(shape=(32, 32, 3)),\n",
    ")\n",
    "\n",
    "vgg.trainable = False\n",
    "\n",
    "x = vgg.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=vgg.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "train_images, test_images = np.split(images, [int(len(images) * 0.8)])\n",
    "train_boxes, test_boxes = np.split(boxes, [int(len(boxes) * 0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3s/step - loss: 0.0713 - val_loss: 0.0385\n",
      "Epoch 2/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - loss: 0.0316 - val_loss: 0.0338\n",
      "Epoch 3/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - loss: 0.0292 - val_loss: 0.0332\n",
      "Epoch 4/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3s/step - loss: 0.0281 - val_loss: 0.0333\n",
      "Epoch 5/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 3s/step - loss: 0.0296 - val_loss: 0.0332\n",
      "Epoch 6/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3s/step - loss: 0.0276 - val_loss: 0.0332\n",
      "Epoch 7/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - loss: 0.0266 - val_loss: 0.0329\n",
      "Epoch 8/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - loss: 0.0271 - val_loss: 0.0328\n",
      "Epoch 9/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1402s\u001b[0m 29s/step - loss: 0.0273 - val_loss: 0.0327\n",
      "Epoch 10/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3s/step - loss: 0.0262 - val_loss: 0.0335\n",
      "Epoch 11/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - loss: 0.0275 - val_loss: 0.0331\n",
      "Epoch 12/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - loss: 0.0263 - val_loss: 0.0326\n",
      "Epoch 13/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 3s/step - loss: 0.0260 - val_loss: 0.0326\n",
      "Epoch 14/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3s/step - loss: 0.0261 - val_loss: 0.0329\n",
      "Epoch 15/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - loss: 0.0262 - val_loss: 0.0330\n",
      "Epoch 16/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 3s/step - loss: 0.0265 - val_loss: 0.0327\n",
      "Epoch 17/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - loss: 0.0266 - val_loss: 0.0333\n",
      "Epoch 18/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - loss: 0.0255 - val_loss: 0.0330\n",
      "Epoch 19/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3s/step - loss: 0.0263 - val_loss: 0.0324\n",
      "Epoch 20/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - loss: 0.0267 - val_loss: 0.0326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26b99753a90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(reduction=\"sum_over_batch_size\", name=\"mse\"),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_boxes,\n",
    "    epochs=20,\n",
    "    validation_data=(test_images, test_boxes),\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - loss: 0.0323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03264449164271355"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "model.evaluate(\n",
    "    test_images,\n",
    "    test_boxes,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "model.save(\"models/vgg_good_20_20.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
